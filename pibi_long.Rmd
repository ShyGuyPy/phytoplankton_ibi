---
title: "pibi_long"
author: "Luke Vawter"
date: "December 21, 2018"
output: 
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '6'
    toc_float: yes
---

####Download Packages
```{r load_packages, message=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(purrr)
library(stringr)
library(leaflet)
library(lubridate)
library(readxl)
library(httr)
library(RCurl)
library(data.table)
library(jsonlite)
library(rprojroot)
library(ritis)
library(parallel)
```

mmir is Zach Smith's custom package
```{r}
#library(mmir)
```


####Funcs and Variables
these varaible should be changed by the user as needed
```{r}
#this is the minimum date to be included
min_date = "1-1-2013"
#this is the minimum date to be included sdd the variable todays.date intot his variable if you want the most recent data
max_date = "12-31-2016"
```

these variables references values found in the API guide at http://datahub.chesapeakebay.net (or int eh case of parameters, fonud from trial and error)
```{r}
#number for picoplankton in CEDR api
pico_num = "18"

#number for phytoplankton in CEDR api
phyto_num <- "17"

#these are the parameter codes for the CEDR api
chla=21
doc=34 
pheo=74 
salinity=83

#data_source = ""
```

variables and functions that will likely not be changed
```{r}
project.dir <- rprojroot::find_rstudio_root_file()

clean_string <- function(x) {
  x %>% 
    stringr::str_trim() %>% 
    tolower() %>% 
    stringr::str_replace_all("\\s+", " ") %>% 
    stringr::str_replace_all(" ", "_") %>%  
    if_else(. == "", as.character(NA), .)
}

clean_up <- function(x) {
  x %>% 
    rename_all(clean_string) %>% 
    mutate_if(is.character, funs(clean_string))%>% 
    distinct()
}

url.root <- "http://datahub.chesapeakebay.net/api.JSON"
todays.date <- format(Sys.Date(), "%m-%d-%Y")


dir.create(file.path(project.dir, "data/VA_ODU/"),
           recursive = TRUE, showWarnings = FALSE)

dir.create(file.path(project.dir, "data/CEDR/"),
           recursive = TRUE, showWarnings = FALSE)

dir.create(file.path(project.dir, "data/MD_DNR/"),
           recursive = TRUE, showWarnings = FALSE)

dir.create(file.path(project.dir, "data/water_quality"),
           recursive = TRUE, showWarnings = FALSE)

dir.create(file.path(project.dir, "data/itis"),
           recursive = TRUE, showWarnings = FALSE)


station.vec <- file.path(url.root,
                       "LivingResources",
                       "TidalPlankton",
                       "Reported",
                       min_date,
                       # "1-1-2013",
                       max_date, 
                       # "12-31-2016",
                       phyto_num,
                       "Station") %>% 
  fromJSON() %>% 
  pull(unique(MonitoringLocationId))

```

####CEDR data



this pulls the sample and event data from cedr
```{r}

phyto.df <- file.path(url.root,
                      "LivingResources",
                      "TidalPlankton",
                      "Reported",
                       min_date,
                       # "1-1-2013",
                       max_date, 
                       # "12-31-2016",
                      phyto_num,
                      "Station",
                      paste(station.vec, collapse = ",")) %>%
  fromJSON() %>% 
  clean_up()




phyto.df %>% 
  mutate(reportingvalue = as.character(reportingvalue)) %>% 
data.table::fwrite(file.path(rprojroot::find_rstudio_root_file(), "data/CEDR", "cedr_phyto_taxa.csv"))





event.df <- file.path(url.root,
                      "LivingResources",
                      "TidalPlankton",
                      "MonitorEvent",
                       min_date,
                       # "1-1-2013",
                       max_date, 
                       # "12-31-2016",
                      phyto_num,
                      "Station",
                      paste(station.vec, collapse = ",")) %>%
  fromJSON() %>% 
  clean_up()





data.table::fwrite(event.df, file.path(rprojroot::find_rstudio_root_file(), "data/CEDR", "cedr_phyto_event.csv"))
```


COMPARE STEP 1
note: both have 824 elements
```{r}
step_1.df <- event.df

data.table::fwrite(step_1.df, file.path(project.dir, "data/test", "step_1.csv"))

s1_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step1.csv")) %>% clean_up() #%>% mutate(sampledate=as.Date(sampledate))
```



pico data(note that the number above "station" is now 18 rather than 17.  The project id for picoplankton is 18, and 17 for phytoplankton)
```{r}
pico.df <- file.path(url.root,
                      "LivingResources",
                      "TidalPlankton",
                      "Reported",
                       min_date,
                       # "1-1-2013",
                       max_date, 
                       # "12-31-2016",
                       pico_num,
                      "Station",
                      paste(station.vec, collapse = ",")) %>%
  fromJSON() %>% 
  clean_up()


pico.df %>% 
  mutate(reportingvalue = as.character(reportingvalue)) %>% #need this?
data.table::fwrite(file.path(project.dir, "data/CEDR/", "cedr_pico_taxa.csv"))
```


### Read csv's t dataframes


You can run the code from here if you've already pulled from the api
CEDR
```{r}
phyto.df <- data.table::fread(file.path(project.dir, "data/CEDR/", "cedr_phyto_taxa.csv")) %>% clean_up() %>% mutate(sampledate=as.Date(sampledate))

event.df <- data.table::fread(file.path(project.dir, "data/CEDR/", "cedr_phyto_event.csv")) %>% clean_up() %>% mutate(sampledate=as.Date(sampledate))

pico.df <- data.table::fread(file.path(project.dir, "data/CEDR/", "cedr_pico_taxa.csv")) %>% clean_up() %>% mutate(sampledate=as.Date(sampledate))

```

####water quality data

download water quality data:
```{r}
wq.df <- file.path(url.root,
                   "WaterQuality",
                   "WaterQuality",

                   min_date,
                   max_date,
                   # format(min(phyto.df$sampledate) - days(3), "%m-%d-%Y"),
                   # format(max(phyto.df$sampledate) + days(3), "%m-%d-%Y"),
                   "6",  #programIds..."6"" or, "2,4,6""
                   "7,23",#"7,16,23,24",  #projectIds
                   "station",
                   paste(station.vec, collapse = ","),
                   paste(
                     chla,doc,pheo,salinity
                     , sep=",")) %>%
                   #"21,34,74,83") %>% #parameter:21=chla, 34=doc, 74=pheo, 83=salinity
  fromJSON() %>% 
  clean_up()

```
"ProjectId":7,"ProjectIdentifier":"MAIN","ProjectName":"Tidal Mainstem Water Quality Monitoring Project"
"ProjectId":16,"ProjectIdentifier":"PART","ProjectName":"Tidal Non-Traditional Partners"
"ProjectId":23,"ProjectIdentifier":"TRIB","ProjectName":"Tidal Tributary Water Quality Monitoring Project"
"ProjectId":24,"ProjectIdentifier":"TSPECIAL","ProjectName":"Special Tidal Water Quality Monitoring Project"

search for mutant ret3.1
```{r}
wq_mutant.df <- wq.df %>%
  filter(eventid == 425680) #%>%
  #filter(is.na(parameter)) 
```

```{r}
missing_other.df <- wq.df %>%
  mutate(sampledate = as.Date(sampledate)) %>%
  #filter(eventid == 394855 %>% 
  filter(totaldepth <= 5 & station %in% c("tf3.3","tf4.2","tf5.5", "ret3.1","ret4.3","ret3.1")) 
  #filter( station %in% c("tf3.3","tf4.2","tf5.5", "ret3.1","ret4.3","ret3.1") &  (is.na(layer)) |!layer %in% c("s","f","m","p", "ap","b", "bp"))
```

this is a check to see if any wq.df sampledate values fall outside of the date range.  None do
```{r}
print(min(wq.df$sampledate))

print(max(wq.df$sampledate))

narrow_date_range.df <-  wq.df %>%
  mutate(sampledate = as.Date(sampledate)) %>%
  filter( sampledate < as.Date("2013-1-1'") |  sampledate > as.Date("2016-12-31"))


```


```{r}
# step_3.df <- wq_w_pdepth.df
# 
# data.table::fwrite(step_3.df, file.path(project.dir, "data/test", "step_3.csv"))

s3_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step3.csv")) %>% clean_up() #%>% mutate(sampledate=as.Date(sampledate))

```


step 3 anti
```{r}
s3_compare_modified.df <- s3_compare.df %>%
  rename(eventid = wq_eventid)


compare_wq_raw.df <- anti_join(wq.df, s3_compare_modified.df, by = c("eventid"))
```


```{r}
station_check <- s3_compare_modified.df %>%
  filter(station %in% c("sbe5"))
```


```{r}
data.table::fwrite(wq.df, file.path(project.dir, "data/water_quality", "cedr_wq.csv"))
```


```{r}
wq.df <- data.table::fread(file.path(project.dir, "data/water_quality/cedr_wq.csv"),
                            data.table = FALSE,
                           na.strings = c(""))
```

run from war wq(right after CEDR pull) note: this is actually STEP 3
we reduce the wq data to match teh phyto data
```{r}
#create concatinated id for phyto events
phyto.df <- phyto.df %>%
  mutate( sampledate =  as.Date(sampledate)) %>%
  mutate(concat = paste0(station, sampledate))

#create concatinated id for water quality data
wq.df <- wq.df %>%
  mutate( sampledate =  as.Date(sampledate)) %>%
  mutate(concat = paste0(station, sampledate))

#create a vector to store concatinated ids from phyto events
concat_vector <- pull(phyto.df, concat)

#include only the data in water quality data that has a matching concat id with phyto events
wq.df <-wq.df %>%
  filter(concat %in% concat_vector) 

```

this snippet of Zach's code removes any row flagged in the problem column(anything other than na)
28 items are removed from the list
do we want this?
```{r}
# wq.df <- wq.df %>%
#   filter(is.na(problem)
        #) 


         #,
         #parameter %in% c("chla", "doc", "pheo", "salinity") ...removed because these are the only 4 parameters included so
         #the code doesn't actually do anything
         
#)
```

selects columns from wq (eventid recently added)
```{r}
wq.df <- wq.df %>%
  select(station, sampledate, layer, depth, parameter, measurevalue, eventid) %>% #eventid,
  mutate(sampledate=as.Date(sampledate))
```

```{r}
# step_3_test.df <- wq.df
# 
# data.table::fwrite(step_3_test.df, file.path(project.dir, "data/test", "step_3_test.csv"))
```


####Prep Event

```{r}
phyto.df <- phyto.df %>%
  mutate(sampledate = as.Date(sampledate))
```

```{r}
event.df <- event.df %>%
  mutate(sampledate = as.Date(sampledate))
```

this is Zach's code for use with use for (I believe) older data that uses older salzone designations,
it's doing nothing for our current data set (2013-2016)
```{r}
event.df <- event.df %>%
  mutate(sampledate = as.Date(sampledate),
         salzone = case_when(
           salzone %in% c("tf", "fe") ~ "f",
           salzone %in% c("m", "me") ~ "m",
           salzone %in% c("o", "oe") ~ "o",
           salzone %in% c("p", "pe") ~ "p",
           TRUE ~ as.character(NA)
         ))
```

```{r}
pdepth.df <- event.df %>%
  filter(layer %in% c("ap","wc")) %>%
  mutate(sampledate = as.Date(sampledate)) %>%
  select(station, sampledate, pdepth) %>%
  dplyr::distinct()
```

COMPARE STEP 2
both 533
```{r}
step_2.df <- pdepth.df

data.table::fwrite(step_2.df, file.path(project.dir, "data/test", "step_2.csv"))

s2_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step2.csv")) %>% clean_up() #%>% mutate(sampledate=as.Date(sampledate))
```


applies pdepth to water quality dataframe
```{r}
wq_w_pdepth.df <- left_join(wq.df, pdepth.df, by = c("station", "sampledate"))
```

determine if depth is above pdepth
with exception for RET stations
```{r}
wq_w_pdepth.df <- wq_w_pdepth.df %>%
  mutate(above_pdepth = case_when(depth <= pdepth~"Yes",
                                  #depth > pdepth & station %in% c("ret3.1","ret4.3","ret3.1")~"No, but RET",
                                  depth > pdepth~"No"

                                  ))
```

```{r}
# test <- wq_w_pdepth.df %>%
#   filter(above_pdepth == "No, but RET")
```


COMPARE STEP 3
note: 7358 to 7358 in Claire's excel
```{r}
step_3.df <- wq_w_pdepth.df

data.table::fwrite(step_3.df, file.path(project.dir, "data/test", "step_3.csv"))

s3_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step3.csv")) %>% clean_up() #%>% mutate(sampledate=as.Date(sampledate))

```

test script for step 3
```{r}
# step_3_test.df <- step_3.df %>%
#   group_by(eventid) %>% #, sampledate) %>%
#   mutate(total_in_group = n()) %>%
#   summarise() %>%
#   ungroup()
#   
# s3_compare.df <- s3_compare.df %>%
#   mutate( sampledate =  as.Date(sampledate, format = '%m/%d/%Y'))
# 
# s3_compare_test.df <- s3_compare.df %>%
#   group_by(wq_eventid) %>%
#   mutate(total_in_group = n()) %>%
#   summarise() %>%
#   ungroup()
# 
# id_vector <- pull(s3_compare_test.df, wq_eventid)
# 
# step_3_by_id <-wq.df %>%
#   filter(eventid %in% id_vector)
# 
# step_3_to_exclude <- wq.df %>%
#   filter(!eventid %in% id_vector)
# 
# s3_wq_dates.df <- data.table::fread(file.path(project.dir, "data/test/", "wq_dates.csv")) %>% clean_up() %>%
#   mutate( sampledate =  as.Date(sampledate, format = '%m/%d/%Y'))
#   # group_by(sampledate) %>%
#   # mutate(total_in_group = n()) %>%
#   # summarise() %>%
#   # ungroup()
# 
# test_7358 <- step_3.df %>%
#   #filter(is.na(problem))
#   filter(layer %in% c("s","a","p","m")) %>%
# 
# test_missing <-  

  
```

filters out dpeths below pdepth
making an exception for any data missing pdepth of station tf4.2
by joining data that meet that criteria back in
```{r}
# missing_pdepth.df <- wq_w_pdepth.df %>%
#   filter( (is.na(pdepth)& station %in% c("tf3.3","tf4.2","tf5.5", "ret3.1","ret4.3","ret3.1")) 
# )
# 
# missing_other_pd.df <- left_join(missing_other.df, pdepth.df, by = c("station", "sampledate")) %>%
#   filter(totaldepth <= 5 & station %in% c("ret3.1","ret4.3") & pdepth <=1 ) 

```

```{r}
wq_above_pdepth.df <- wq_w_pdepth.df%>%
  filter(depth <= pdepth)


#wq_above_pdepth.df <- full_join(wq_above_pdepth.df, missing_pdepth.df)

#& (!station %in% c("tf3.3","tf4.2","tf5.5", "ret3.1","ret4.3","ret3.1") & layer != "ap"))


```


check for missing(station and date combos that are present in event.df but not represtented in wq_above_pdepth.df) 
```{r}
step_4.vec <- c("station", "sampledate", "layer", "pdepth", "concat", "depth", "parameter", "measurevalue", "above_pdepth", "eventid")

#function for finding backbone values missing from recently modified data and add them into recently modified(latest) date
find_missing <- function(data_backbone, source_data, modified_data, step_vector) {
  missing.df <- anti_join(data_backbone, modified_data, by = c("station","sampledate"))
  
  missing.df <-  missing.df %>%
    mutate( sampledate =  as.Date(sampledate)) %>%
    mutate(concat = paste0(station, sampledate))
  
  source_data <- source_data %>%
    mutate( sampledate =  as.Date(sampledate)) %>%
    mutate(concat = paste0(station, sampledate))
  
  concat_vector2.vec <- pull(missing.df, concat)
  
  missing_full.df <-source_data %>%
    filter(concat %in% concat_vector2.vec) 
  
  modified_data <- modified_data %>%
  mutate( sampledate =  as.Date(sampledate)) %>%
  mutate(concat = paste0(station, sampledate))

  final.df <- full_join(modified_data, missing_full.df, by = step_vector)
                          #c("station", "sampledate", "layer", "pdepth", "concat", "depth", "parameter", "measurevalue", "above_pdepth", "eventid"))
  
  return(final.df)
}
#show the mssing values
name_missing <- function(data_backbone, source_data, modified_data, step_vector) {
  missing.df <- anti_join(data_backbone, modified_data, by = c("station","sampledate"))
  
  missing.df <-  missing.df %>%
    mutate( sampledate =  as.Date(sampledate)) %>%
    mutate(concat = paste0(station, sampledate))
  
  source_data <- source_data %>%
    mutate( sampledate =  as.Date(sampledate)) %>%
    mutate(concat = paste0(station, sampledate))
  
  concat_vector2.vec <- pull(missing.df, concat)
  
  final.df <-source_data %>%
    filter(concat %in% concat_vector2.vec) 
  
    return(final.df)
}

wq_above_pdepth.df <- find_missing(event.df, wq_w_pdepth.df, wq_above_pdepth.df, step_4.vec)

# #finds instances of station/sampledate combo that are missing from wq
# missing.df <- anti_join(event.df,wq_above_pdepth.df, by = c("station", "sampledate"))
# 
# #standardize date format and add a unique identifier to missing 
# missing.df <- missing.df %>%
#   mutate( sampledate =  as.Date(sampledate)) %>%
#   mutate(concat = paste0(station, sampledate))
# 
# #standardize date format and add a unique identifier to wq
# wq_w_pdepth.df <- wq_w_pdepth.df %>%
#   mutate( sampledate =  as.Date(sampledate)) %>%
#   mutate(concat = paste0(station, sampledate))
# 
# #create a vector to store concatinated ids from the missing combos
# concat_vector2.vec <- pull(missing.df, concat)
# 
# #uses the combos in missing.df to retrieve the event data for the missing values
# missing_full.df <-wq_w_pdepth.df %>%
#   filter(concat %in% concat_vector2.vec) 
# 
# #adds a concat id to wq_above_pdepth
# wq_above_pdepth.df <- wq_above_pdepth.df %>%
#   mutate( sampledate =  as.Date(sampledate)) %>%
#   mutate(concat = paste0(station, sampledate))
# 
# #joins the missing values back into most recent wq df
# wq_above_pdepth.df <- full_join(wq_above_pdepth.df, missing_full.df, by = c("station", "sampledate", "layer", "pdepth", "concat", "depth", "parameter", "measurevalue", "above_pdepth", "eventid"))
```


COMPARE STEP 4
note: 3483 to 3483 in Claire's excel
```{r}
step_4.df <- wq_above_pdepth.df

data.table::fwrite(step_4.df, file.path(project.dir, "data/test", "step_4.csv"))

s4_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step4.csv")) %>% clean_up() #%>% mutate(sampledate=as.Date(sampledate))
```

code to compare dataframes for testing step 4:
```{r}
step_4_modified.df <- step_4.df %>%
  mutate(sampledate = as.Date(sampledate)) %>%
  #select(-sampledate, above_pdepth) %>%
  mutate(author = "Luke")

# s4_compare.df <- s4_compare.df %>%
#   mutate(sampledate = as.Date(sampledate))

s4_compare_modified.df <- s4_compare.df %>%
  rename(above_pdepth = `above_p_depth?`) %>%
  rename(eventid = wq_eventid) %>%
  rename(pdepth = p_depth) %>%
  select(station, sampledate, layer, depth, parameter, measurevalue, eventid, pdepth, above_pdepth) %>%
  #select(-sampledate, -above_pdepth) %>%
  mutate(author = "Claire")


```


the objects in diff_check_step_4.df were the 4 entries that exist in Claire's data but not in mine. Exceptions written for such cases, except one which does not exist in my data:
```{r}

#diff_check.df <- left_join(step_4_modified.df, s4_compare_modified.df)


LV_diff_check_step_4.df <- anti_join(step_4_modified.df, s4_compare_modified.df, by = c("station", "depth", "parameter", "measurevalue", "eventid", "pdepth")) #"layer",

C_diff_check_step_4.df <- anti_join(s4_compare_modified.df, step_4_modified.df,  by = c("station", "depth", "parameter", "measurevalue", "eventid", "pdepth")) #"layer",

# author_check.df <- diff_check.df %>%
#   filter(author == "Claire")
```


Step 5:

this code isolates exceptions that need to be added back in after the following chunk of code
```{r}
# 
# step5_exceptions <- wq_above_pdepth.df %>%
#   filter(above_pdepth == "No, but RET")
#   filter(!layer %in% c("s","f","m","p", "ap"))

```


generates new dataframe with new parameter s_chla (531 items, should be 533)
```{r}
s_chla.df <- wq_above_pdepth.df %>%
  filter(layer == "s", 
         parameter == "chla") %>% 
  unite(parameter, c("layer", "parameter"), remove = FALSE) #%>%
  # filter(depth <= pdepth) #%>%
  #filter(parameter=="s_chla")
  #filter(eventid==425680 | eventid==394855)
```

```{r}
# s_chla.df <- s_chla.df %>%
#   group_by(station, sampledate) %>%
#   mutate(avg_di_s_chla = mean(measurevalue, na.rm = TRUE)) %>%
#   ungroup()
```

Average replicates from s_chla ...measure value average
```{r}
di_s_chla.df <- s_chla.df %>%
  group_by(station, sampledate, depth) %>%
  #do not remove NAs
  mutate(measurevalue_averaged = mean(measurevalue)) %>%
  distinct(station, sampledate, depth, eventid, layer, parameter, measurevalue_averaged, concat) %>%
  ungroup()

```


find missing values in step 5
```{r}
step_5.vec <- c("station", "sampledate", "layer", "concat", "depth", "parameter", "eventid")


#grabs missing values
missing_s_chla.df <- name_missing(event.df, wq_above_pdepth.df, di_s_chla.df, step_5.vec) %>%
  #reduce to only a single isntance for each eventid
  distinct(eventid, station, sampledate, concat) %>%
  mutate(parameter =  "s_chla") %>%
  mutate(sampledate = as.Date(sampledate)) %>%
  mutate()

# creates a vector of the unqiue ids of the missing values
missing_ids.vec <- pull(missing_s_chla.df, eventid) 

# checks ids against source, which is totally redundant
missing_full.df <-wq_above_pdepth.df %>%
  filter(eventid %in% missing_ids.vec ) 

#join missing values into di_s_chla.df with blank values
di_s_chla.df <- full_join(di_s_chla.df, missing_s_chla.df, by = c("station", "sampledate", "eventid", "parameter", "concat"))

# test.df <- di_s_chla_test.df %>%
#   filter(is.na(measurevalue_averaged))
  
```


I have eventid 39855 with s_chla in my wq data
this is the check:
```{r}
mystrey.df <- wq_above_pdepth.df %>%
  filter(eventid == 394855)

mysery2.df <- event.df %>%
  filter(station == "tf4.2" & sampledate =="2014-07-15")
  
mystery3.df <- wq.df %>%
  filter(eventid == 394855)

mystery4.df <- di_s_chla.df %>%
  filter(eventid == 394855)
```




STEP 5 COMPARE
my 533 to Claire's 531(was 533?)
```{r}
step_5.df <- di_s_chla.df

data.table::fwrite(step_5.df, file.path(project.dir, "data/test", "step_5.csv"))

s5_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step5.csv")) %>% clean_up() #%>% mutate(sampledate=as.Date(sampledate))
```

```{r}
step_5_modified.df <- step_5.df %>%
  mutate(sampledate = as.Date(sampledate)) %>%
  #select(-sampledate, above_pdepth) %>%
  mutate(author = "Luke") %>%
  clean_up() %>%
  mutate(measurevalue_averaged = as.numeric(measurevalue_averaged))

# s5_compare.df <- s5_compare.df %>%
#   mutate(sampledate = as.Date(sampledate))

s5_compare_modified.df <- s5_compare.df %>%
  rename(eventid = wq_eventid) %>%
  rename(measurevalue_averaged = average_of_measurevalue) %>%
  #rename(pdepth = p_depth) %>%
  #select(station, sampledate, layer, depth, parameter, measurevalue, eventid, pdepth, above_pdepth) %>%
  #select(-sampledate, -above_pdepth) %>%
  mutate(author = "Claire") %>%
  clean_up() %>%
  mutate(measurevalue_averaged = as.numeric(measurevalue_averaged))


C_diff_check_step_5.df <- anti_join(s5_compare_modified.df, step_5_modified.df, by = c("station",  "parameter", "measurevalue_averaged", "eventid", "layer"))

C_diff_check_step_5.df <- C_diff_check_step_5.df%>%
  mutate(measure_type = typeof(measurevalue_averaged)) %>%
  filter(eventid==425680 | eventid==394855)

LV_diff_check_step_5.df <- anti_join(step_5_modified.df, s5_compare_modified.df, by = c("station", "measurevalue_averaged", "parameter", "eventid","layer")) 

LV_diff_check_step_5.df <- LV_diff_check_step_5.df%>%
  mutate(measure_type = typeof(measurevalue_averaged))
```


```{r}
# wq_rep_check.df <- wq_above_pdepth.df %>%
#   select(station, sampledate, depth, parameter) %>%
#   distinct()
```



Averge replicates for the rest of the data ...measure value average 
```{r}
wq_above_pdepth.df <- wq_above_pdepth.df %>%
  group_by(station, sampledate, depth, parameter) %>%
  #do not remove NAs
  mutate(measurevalue_averaged = mean(measurevalue)) %>%
  distinct(station, sampledate, depth, parameter,measurevalue_averaged) %>%
  ungroup()
```

COMPARE STEP 6 
my 3366 to Claire's is 3357(was 3366)
```{r}
step_6.df <- wq_above_pdepth.df

data.table::fwrite(step_6.df, file.path(project.dir, "data/test", "step_6.csv"))

s6_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step6.csv")) %>% clean_up()

C_diff_check_step_6.df <- anti_join(step_6.df,s6_compare.df, by = c(
  #"station", "depth","parameter", 
  "measurevalue_averaged"
  )) 

LV_diff_check_step_6.df <- anti_join(s6_compare.df, step_6.df, by = c(
  #"station", "depth", "parameter", 
  "measurevalue_averaged")) 


```


```{r}
wq_above_pdepth.df <- wq_above_pdepth.df %>%
  group_by(station, sampledate, parameter) %>%
  mutate(depth_integrated_value = mean(measurevalue_averaged)) %>%
  distinct(station, sampledate, depth_integrated_value) %>%
  ungroup()
```

COMPARE STEP 7 
mine is 2028 to Claire's 2026(was 2028)
```{r}
step_7.df <- wq_above_pdepth.df

data.table::fwrite(step_7.df, file.path(project.dir, "data/test", "step_7.csv"))

s7_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step7.csv")) %>% clean_up() %>% 
  rename(depth_integrated_value =`depth-integrated_value`)


C_diff_check_step_7.df <- anti_join(step_7.df,s7_compare.df, by = c(#"station", "parameter", 
  "depth_integrated_value")) 

LV_diff_check_step_7.df <- anti_join(s7_compare.df, step_7.df, by = c(#"station", "parameter", 
  "depth_integrated_value")) 
```

join surface chloraphyl into water quality data
measurevalued_averaged is renamed depth_integrated_value to match water quality naming convention
(note:check against Claire's data to confirm that s_chla depth integrated values look right just to be sure)
```{r}
di_s_chla.df <- di_s_chla.df %>% 
  rename(depth_integrated_value = measurevalue_averaged)
  

wq_all.df <- full_join(wq_above_pdepth.df, di_s_chla.df, by = c("station", "sampledate", "parameter", "depth_integrated_value"))

# wq_all.df <- wq_all.df %>%
#   filter(parameter != "s_chla")
  
```


COMPARE STEP 8
my 2561 to Claire's 2555(was 2558)
```{r}
print(2028 + 533)


step_8.df <- wq_all.df

data.table::fwrite(step_8.df, file.path(project.dir, "data/test", "step_8.csv"))

s8_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step8.csv")) %>% clean_up() %>% 
  rename(depth_integrated_value =`depth-integrated_value`)

C_diff_check_step_8.df <- anti_join(step_8.df,s8_compare.df, by = c("depth_integrated_value")) 

LV_diff_check_step_8.df <- anti_join(s8_compare.df, step_8.df, by = c("depth_integrated_value")) 
```

filter out dates outside Mar-May and Jul-Sept
borrowed this chunck from Zach
```{r}
wq_warm.df <- wq_all.df %>%
  mutate(month = month(sampledate),
         season = case_when(
           month %in% c(3, 4, 5) ~ "spring",
           month %in% c(7, 8, 9) ~ "summer",
           TRUE ~ "remove"
          )) 
  #%>% 
  # filter(season %in% c("spring", "summer"))
```


assign salzones...work in progress
```{r}
wq_sal.df <- wq_warm.df %>%
  filter(parameter == "salinity")

wq_sal.df <- wq_sal.df %>%
  mutate(salzone = case_when(
    parameter == "salinity" & depth_integrated_value >0 & depth_integrated_value <= 0.5 ~ "F",
    parameter == "salinity" & depth_integrated_value > .5 &  depth_integrated_value <= 5 ~ "O",
    parameter == "salinity" & depth_integrated_value > 5 & depth_integrated_value <= 18 ~ "M",
    parameter == "salinity" & depth_integrated_value > 18~ "P")) %>%
    mutate(concat = paste0(station, sampledate)) 

wq_sal_id.df <- wq_sal.df %>%
  distinct(concat, salzone)

wq_warm.df <- wq_warm.df %>%
    mutate(concat = paste0(station, sampledate))   


wq_warm_sal.df <- left_join(wq_warm.df, wq_sal_id.df, by = c("concat"))#, "salzone"))



```




Find events without salinity and assign salinity when possible...Assign F salzone to some station/season instances based on known salinity profiles
```{r}
# salinities are less than 0.5 ppt, or "F" more than 90% of the time: CB1.1, ET5.1, TF1.5, TF2.3, TF4.2, TF5.5 in Spring;								
# CB1.1, TF2.3, TF4.2, TF5.5 in Summer. We can assume their Salzone is F and replace 61 of the 78 blanks.								
wq_no_sal.df <- anti_join(wq_warm_sal.df, wq_sal_id.df, by = c("concat"))

wq_sal_fill.df <-  wq_no_sal.df %>%
  distinct(concat, station, sampledate, season, salzone) %>%
  mutate(salzone = case_when((station %in% c("cb1.1", "tf2.3", "tf4.2","tf5.5" ) & is.na(salzone)) | (season == "spring" & station %in% c("et5.1", "tf1.5")& is.na(salzone))
         ~ "F", TRUE ~ salzone  ))

#test number of exceptions above code is catching
wq_sal_filled.df <- wq_sal_fill.df %>%
  filter(salzone == "F")

test_na.df <- wq_sal_fill.df %>%
  filter(is.na(salzone))
```

Add the data assigned salzones back into backbone
```{r}
wq_warm_sal_added.df <- left_join(wq_warm_sal.df, wq_sal_filled.df, by= c("concat", "salzone","station","sampledate", "season"))

# test to determine if we are retaining the right values
test.df <- anti_join(wq_warm.df, wq_warm_sal_added.df,  by = c("concat", "station","sampledate", "season", "parameter", "month", "depth_integrated_value"))
```



bring in Jackies data to compare salzones against
import jackie's salzones if data falls within the applicable date range and is missing salzone data
note:this should be the last method of acquiring salzone data implemented
```{r}
#jackie.df <- data.table::fread(file.path(project.dir, "data/Jackie/", "JMJ_PIBI_Salzone_Data.csv"))
jackie_salzones.df <- readxl::read_excel(file.path(project.dir, "data/Jackie/JMJ_PIBI_Salzone_Data.xlsx"),
                         sheet = "JMJ Salzone+Scores") %>% clean_up() 

wq_need_sal.df <- wq_sal_test.df %>%
  mutate(year = year(sampledate)) %>%
  filter(year >= 1984 & year <= 2011 & is.na(salzone))

#join jackie salzone values to wq_need_sal by id
wq_has_sal.df <- left_join(wq_need_sal.df, jackie_salzones.df, by= c("concat", "salzone"))

#join wq_need_sal to main wq data
wq_has_sal.df <- left_join(wq_sal_test.df, wq_has_sal.df, by= c("concat", "salzone"))
             
```


```{r}
wq_warm.wide <- wq_warm_sal_added.df %>%
  select(-layer, -depth,-eventid,-concat) %>%
  spread(parameter, depth_integrated_value)
```


COMPARE STEP 9
```{r}
step_9.df <- wq_warm.wide

data.table::fwrite(step_9.df, file.path(project.dir, "data/test", "step_9.csv"))

s9_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step9.csv")) %>% clean_up() 

C_diff_check_step_9.df <- anti_join(step_9.df,s9_compare.df, by = c("chla", "s_chla", "pheo", "salinity", "doc")) 

LV_diff_check_step_9.df <- anti_join(s9_compare.df, step_9.df, by = c("chla", "s_chla", "pheo", "salinity", "doc")) 
```

remove winter and fall
```{r}
wq_final.df <- wq_warm.wide %>%

 filter(season %in% c("spring", "summer"))
```
COMPARE STEP 10

```{r}
step_10.df <- wq_final.df

data.table::fwrite(step_10.df, file.path(project.dir, "data/test", "step_10.csv"))

s10_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step10.csv")) %>% clean_up() 

C_diff_check_step_10.df <- anti_join(step_10.df,s10_compare.df, by = c("chla", "s_chla", "pheo", "salinity", "doc")) 

LV_diff_check_step_10.df <- anti_join(s10_compare.df, step_10.df, by = c("chla", "s_chla", "pheo", "salinity", "doc"))
```




Taxanomic steps
currently using Zach's code mostly unmodified at this point(change as needed)

update TSNs

```{r}
col.class.vec <- c("samplenumber" = "character",
                   "tsn" = "character",
                   "speccode" = "character",
                   "reportingvalue" = "integer")

bay.temp <- data.table::fread(file.path(project.dir,  "data/CEDR/cedr_phyto_taxa.csv"
                                        #"data/phytoplankton2/VA_ODU_phyto_taxa.csv"
                                        ),
                            data.table = FALSE,
                            colClasses = col.class.vec)
```


grab old carbon
```{r}
carbon.df <- readxl::read_excel(file.path(project.dir, "data/carbon/carbon_list_2014.xlsx"),
                                sheet = "carbon_list_2014") %>% 
  clean_up() %>% 
  
  #deselcting several fields
  dplyr::select(-dplyr::contains("new"),
                -smyayda_carbon,
                -difference,
                -shape_change) %>% 
  dplyr::rename(carbon = old_carbon)
```























extracting depth integrated dataframe for each parameter
note:doc has 560, and salinity 1585 items where all others have 666
this is another way of doing
STEP 7
```{r}
# di_doc.df <- wq_above_pdepth.df %>%
#   #filter(depth <= pdepth) %>%
#   filter(parameter=="doc") %>%
# 
#   group_by(station, sampledate) %>%
#   mutate(avg_di_doc = mean(measurevalue_averaged, na.rm = TRUE)) %>%
#   ungroup()
# 
# di_chla.df <- wq_above_pdepth.df %>%
#   #filter(depth <= pdepth) %>%
#   filter(parameter == "chla") %>%
# 
#   group_by(station, sampledate) %>%
#   mutate(avg_di_chla = mean(measurevalue_averaged, na.rm = TRUE)) %>%
#   ungroup()
# 
# di_salinity.df <- wq_above_pdepth.df %>%
#   #filter(depth <= pdepth) %>%
#   filter(parameter == "salinity") %>%
# 
#   group_by(station, sampledate) %>%
#   mutate(avg_di_salinity = mean(measurevalue_averaged, na.rm = TRUE)) %>%
#   ungroup()
# 
# di_pheo.df <- wq_above_pdepth.df %>%
#   #filter(depth <= pdepth) %>%
#   filter(parameter == "pheo") %>%
# 
#   group_by(station, sampledate) %>%
#   mutate(avg_di_pheo = mean(measurevalue_averaged, na.rm = TRUE)) %>%
#   ungroup()

#step7 <- left_join(di_doc.df, di_chla.df, di_salinity.df, di_pheo.df, by = c("station", "sampledate"))

#join the four dataframes created above into one dataframe

# wq_all.df <- Reduce(function(x, y) merge(x, y, all=TRUE), list(di_doc.df, di_chla.df,di_salinity.df,di_pheo.df))
```

C-  need to apply this to all sample, date combos but want to review with Claire first
```{r}
# di_salinity.df <-di_salinity.df %>%
# 
#   mutate(salzone = case_when(
#     avg_di_salinity >0 & avg_di_salinity <= 0.5 ~ "F",
#     avg_di_salinity > .5 &  avg_di_salinity <= 5 ~ "O",
#     avg_di_salinity > 5 & avg_di_salinity <= 18 ~ "M",
#     avg_di_salinity > 18~ "P")
#   )
```

```{r}
#wq_joined.df <- left_join(di_doc.df, di_chla.df,di_salinity.df,di_pheo.df, by = c("station", "sampledate"))
wq_all.df <- Reduce(function(x, y) merge(x, y, all=TRUE), list(di_doc.df, di_chla.df,di_salinity.df,di_pheo.df))#, s_chla.df))

di_wq_all.df <- wq_all.df %>%
  filter(above_pdepth == TRUE) #depth <= pdepth) 
```



assign salzones

```{r}
wq_all.df <- wq_all.df %>%
  mutate(salzone = case_when(
    avg_di_salinity >0 & avg_di_salinity <= 0.5 ~ "F",
    avg_di_salinity > .5 &  avg_di_salinity <= 5 ~ "O",
    avg_di_salinity > 5 & avg_di_salinity <= 18 ~ "M",
    avg_di_salinity > 18~ "P"))
```


```{r}
# wq_sz.df <- wq_all.df %>%
#   select(station, sampledate, salzone) %>%
#   distinct() %>%
#   filter(!is.na(salzone))
```

```{r}
# sal.df <- wq_all.df %>%
#   group_by(station, sampledate) %>%
#   mutate(apple= case_when(parameter == "salinity"~avg_di_salinity, 
#                           parameter %in% c("pheo", "doc", "chla")~0)
#          ) %>%
#   summarise(apple = max(apple)) %>%
#   ungroup() 
# 
# wq_sal.df <- left_join(wq_all.df, sal.df, by = c("station", "sampledate"))
```

generate dataframe...
```{r}
sal.df <- wq_all.df %>%
  mutate(avg_di_salinity= case_when(parameter %in% c("pheo", "doc", "chla")~0, TRUE~avg_di_salinity)
         ) %>%
  filter(!is.na(avg_di_salinity))

sal.df <- sal.df %>%
  group_by(station, sampledate) %>%
  summarise(avg_di_salinity = max(avg_di_salinity)) %>%
  ungroup() 
```


```{r}
wq_all.temp<- wq_all.df %>%
  select(-avg_di_salinity)

#wq_all_test.df < left_join(wq_all.temp, sal.df, by = c("station", "sampledate"))
wq_all_test.df <- Reduce(function(x, y) merge(x, y, all=TRUE), list(wq_all.temp, sal.df))
  
```

assign salzones
```{r}
wq_sal.df <-wq_all_test.df %>%

  mutate(salzone = case_when(
    avg_di_salinity >0 & avg_di_salinity <= 0.5 ~ "F",
    avg_di_salinity > .5 &  avg_di_salinity <= 5 ~ "O",
    avg_di_salinity > 5 & avg_di_salinity <= 18 ~ "M",
    avg_di_salinity > 18~ "P")
  )
```


###Taxanmoic data (ITIS)

this is Zach's code.  It's pretty neat.
```{r}
col.class.vec <- c("samplenumber" = "character",
                   "tsn" = "character",
                   "speccode" = "character",
                   "reportingvalue" = "integer")

bay.temp <- data.table::fread(file.path(project.dir,  "data/CEDR/cedr_phyto_taxa.csv"
                                        #"data/phytoplankton2/VA_ODU_phyto_taxa.csv"
                                        ),
                            data.table = FALSE,
                            colClasses = col.class.vec)
```

this test shows that 1794 have a tsn of 0(Zach explains there are no na, only 0, which is annoying)
```{r}
need_tsn.df <- bay.temp %>%
  filter(tsn==0)
```

tsn assignment code(reduces number of tsn not assinged to 1514 from 1794)
```{r}
taxa.df <- bay.temp %>% 
  mutate(
    tsn = as.integer(tsn),
    tsn = case_when(
      latinname == "navicula_notablis" ~ as.integer(4327),
      latinname == "pleurosigma_macrum" ~ as.integer(4650),
      latinname == "pleurosigma_obscurum" ~ as.integer(591383),
      latinname == "polykrikos_hartmannii" ~ as.integer(331299),
      latinname == "protoperidinium_aciculiderum" ~ as.integer(10329),
      latinname == "protoperidinium_paulseni" ~ as.integer(3568),
      latinname == "scrippsiella_favionese" ~ as.integer(10537),
      latinname == "tetrastrum_caudatum" ~ as.integer(5691),
      latinname == "didymocystis" ~ as.integer(5810),
      latinname == "lauterborniella_elegantissima" ~ as.integer(6097),
      latinname == "characium_sp." ~ as.integer(5756),
      latinname == "cylindrospermopsis_sp." ~ as.integer(203689),
      latinname == "chaetoceros_neogracilis" ~ as.integer(1004011),
      latinname == "navicula_retusa_cancellata" ~ as.integer(1020372),
      latinname == "karlodinium_micrum" ~ as.integer(180904),
      latinname == "lagerheimia" ~ as.integer(6017),
      latinname == "quadricoccus_euryhalinicus" ~ as.integer(957939),
      latinname == "scrippsiella_precaria" ~ as.integer(10536),
      latinname == "psuedosolenia_calcar-avis" ~ as.integer(970064),
      latinname == "centronella" ~ as.integer(970064),
      latinname == "amphidinium_tatrae" ~ as.integer(9997),
      latinname == "navicula_lata" ~ as.integer(4450),
      latinname == "nitzschia_vitrea_recta" ~ as.integer(5204),
      latinname == "rhaphoneis_gemmifera" ~ as.integer(3145),
      latinname == "delphineis_surirella" ~ as.integer(969978),
      latinname == "navicula_annulata" ~ as.integer(3649),
      latinname == "proboscia_alata_gracillima" ~ as.integer(610099),
      latinname == "guinardia_striata" ~ as.integer(2921),
      latinname == "guinardia_cylindrus" ~ as.integer(2921),
      latinname == "aphanizomenon_issatschenkoi" ~ as.integer(1191),
      latinname == "helicotheca_tamesis" ~ as.integer(590815),
      latinname == "corethron_valdivae" ~ as.integer(2386),
      latinname == "gonyaulax_conjuncta" ~ as.integer(10359),
      latinname == "lioloma_delicatulum" ~ as.integer(573597),
      latinname == "syracosphaera_histrica" ~ as.integer(2234),
      latinname == "rhizosolenia_formosa" ~ as.integer(2879),
      latinname == "proboscla_alata_curvirostris" ~ as.integer(610099),
      latinname == "membraneis_challengeri" ~ as.integer(3648),
      latinname == "chrysococcus_tesselatus" ~ as.integer(1751),
      latinname == "rhoicosphenia_abbreviata" ~ as.integer(3633),
      latinname == "protoperidinium_aciculiferum" ~ as.integer(10340),
      latinname == "protoperidinium_fimbriatum" ~ as.integer(10340),
      latinname == "licmophora_inflata" ~ as.integer(3155),
      latinname == "biddulphia_reticulata" ~ as.integer(2678),
      latinname == "caloneis_lepidula" ~ as.integer(4369),
      latinname == "caloneis_trinodis" ~ as.integer(4369),
      latinname == "amphiprora_cholnokyi" ~ as.integer(4674),
      latinname == "navicula_interrupta" ~ as.integer(3649),
      latinname == "cerataulus_radiatus" ~ as.integer(2709),
      latinname == "gyrosigma_balticum_silimis" ~ as.integer(4623),
      latinname == "dictyocha_siderea" ~ as.integer(1804),
      latinname == "odontella_alternans" ~ as.integer(573604),
      latinname == "nitzschia_vitrea_salinarum" ~ as.integer(5204),
      latinname == "proboscla_alata_indica" ~ as.integer(610099),
      latinname == "attheya_decora" ~ as.integer(2876),
      latinname == "synedra_closterioides" ~ as.integer(970065),
      latinname == "trinacria_regina" ~ as.integer(2747),
      latinname == "chattonella" ~ as.integer(969917),
      latinname == "chattonella_subsalsa" ~ as.integer(969917),
      latinname == "heterosigma_akashiwo" ~ as.integer(969917),
      latinname == "vibrio_fisheri" ~ as.integer(959178),
      TRUE ~ as.integer(tsn)
    )
  )
```

```{r}
taxa_need_tsn.df <- taxa.df %>%
  filter(tsn==0)
``` 

changed all org_tsn references to tsn, because org_tsn does not exist in bay.temp.
Also, first row is na's and 0's suggesting that the data has a space between the header, and that total number of
ojects(3065) may be one over our actual values
```{r}
hier.wide <- lapply(unique(bay.temp$tsn), function(tsn.i) {
 #print(tsn.i)
  
  if(ncol(usage(tsn.i)) == 0) return(data.frame(tsn = as.integer(tsn.i),
                                                stringsAsFactors = FALSE))
  if(!ritis::usage(tsn.i)$taxonUsageRating %in% c("accepted", "valid")) {
    tsn.accepted <- ritis::accepted_names(as.integer(tsn.i))$acceptedTsn
  } else {
    tsn.accepted <- as.integer(tsn.i)
  }

  full.df <- ritis::hierarchy_full(tsn.accepted) %>%
    select(rankname, taxonname, tsn) %>%
    slice(1:which(tsn == tsn.accepted)) %>%
    mutate(tsn = as.integer(tsn.i),
           final_tsn = as.integer(tsn.accepted),
           final_id = slice(., which(tsn == tsn.accepted))$taxonname)
}
) %>%
  bind_rows() %>%
#   select(-tsn) %>% 
  #spread(rankname, taxonname) %>%
  clean_up()
```

removes the gap mentioned above
```{r}
hier.wide<- hier.wide %>%
  filter(!is.na(taxonname) & !is.na(rankname))
```

```{r}
column.vec <- c("org_tsn", "final_tsn", "final_id",
                "kingdom", "subkingdom", "infrakingdom", 
                "superdivision", "division", "subdivision", "infradivision",
                "superphylum", "phylum", "subphylum", "infraphylum", 
                "superclass", "class", "subclass", "infraclass", 
                "superorder", "order", "suborder", "infraorder", 
                "superfamily", "family", "subfamily", 
                "tribe", "subtribe", 
                "genus", "subgenus", 
                "species", "subspecies")

column.vec <- column.vec[column.vec %in% names(hier.wide)]
```

save the itis data to a csv
```{r}


data.table::fwrite(hier.wide, file.path(rprojroot::find_rstudio_root_file(), "data/itis", "itis_hierarchy.csv"))
```


####Testing
```{r}
# na <- stat_samp %>%
#   filter(is.na(stat_samp$pdepth))
# 
# not_na <- stat_samp %>%
#   filter(!is.na(stat_samp$pdepth))

# pico.df <- file.path(url.root,
#                       "LivingResources",
#                       "TidalPlankton",
#                       "Reported",
#                        min_date,
#                        # "1-1-2013",
#                        max_date, 
#                        # "12-31-2016",
#                       #"Picoplankton",
#                        "18",
#                       "Station",
#                       paste(station.vec, collapse = ",")) %>%
#   fromJSON() %>% 
#   clean_up()
# 
# stat <- pico_test.df %>%
#   select(station) %>%
#   distinct()

# no_p.df<- pdepth.df %>%
#   filter(!station%in%c("tf3.3","tf4.2","tf5.5","ret3.1","ret4.3","ret3.1") & is.na(pdepth) & layer %in% c("ap", "wc"))


            

```

