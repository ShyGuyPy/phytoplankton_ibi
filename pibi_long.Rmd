---
title: "pibi_long"
author: "Luke Vawter"
date: "December 21, 2018"
output: 
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '6'
    toc_float: yes
---

####Download Packages
```{r load_packages, message=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(purrr)
library(stringr)
library(leaflet)
library(lubridate)
library(readxl)
library(httr)
library(RCurl)
library(data.table)
library(jsonlite)
library(rprojroot)
library(ritis)
library(parallel)
```

mmir is Zach Smith's custom package
```{r}
#library(mmir)
```


####Funcs and Variables
these varaible should be changed by the user as needed
```{r}
#this is the minimum date to be included
min_date = "1-1-2013"
#this is the minimum date to be included sdd the variable todays.date intot his variable if you want the most recent data
max_date = "12-31-2016"
```

these variables references values found in the API guide at http://datahub.chesapeakebay.net (or int eh case of parameters, fonud from trial and error)
```{r}
#number for picoplankton in CEDR api
pico_num = "18"

#number for phytoplankton in CEDR api
phyto_num <- "17"

#these are the parameter codes for the CEDR api
chla=21
doc=34 
pheo=74 
salinity=83

#data_source = ""
```

variables and functions that will likely not be changed
```{r}
project.dir <- rprojroot::find_rstudio_root_file()

clean_string <- function(x) {
  x %>% 
    stringr::str_trim() %>% 
    tolower() %>% 
    stringr::str_replace_all("\\s+", " ") %>% 
    stringr::str_replace_all(" ", "_") %>%  
    if_else(. == "", as.character(NA), .)
}

clean_up <- function(x) {
  x %>% 
    rename_all(clean_string) %>% 
    mutate_if(is.character, funs(clean_string))%>% 
    distinct()
}

url.root <- "http://datahub.chesapeakebay.net/api.JSON"
todays.date <- format(Sys.Date(), "%m-%d-%Y")


dir.create(file.path(project.dir, "data/VA_ODU/"),
           recursive = TRUE, showWarnings = FALSE)

dir.create(file.path(project.dir, "data/CEDR/"),
           recursive = TRUE, showWarnings = FALSE)

dir.create(file.path(project.dir, "data/MD_DNR/"),
           recursive = TRUE, showWarnings = FALSE)

dir.create(file.path(project.dir, "data/water_quality"),
           recursive = TRUE, showWarnings = FALSE)

dir.create(file.path(project.dir, "data/itis"),
           recursive = TRUE, showWarnings = FALSE)


station.vec <- file.path(url.root,
                       "LivingResources",
                       "TidalPlankton",
                       "Reported",
                       min_date,
                       # "1-1-2013",
                       max_date, 
                       # "12-31-2016",
                       phyto_num,
                       "Station") %>% 
  fromJSON() %>% 
  pull(unique(MonitoringLocationId))

```

####CEDR data



this uploads the sample and event data from cedr to a dataframe(phyto.df)
```{r}

phyto.df <- file.path(url.root,
                      "LivingResources",
                      "TidalPlankton",
                      "Reported",
                       min_date,
                       # "1-1-2013",
                       max_date, 
                       # "12-31-2016",
                      phyto_num,
                      "Station",
                      paste(station.vec, collapse = ",")) %>%
  fromJSON() %>% 
  clean_up()




phyto.df %>% 
  mutate(reportingvalue = as.character(reportingvalue)) %>% 
data.table::fwrite(file.path(rprojroot::find_rstudio_root_file(), "data/CEDR", "cedr_phyto_taxa.csv"))





event.df <- file.path(url.root,
                      "LivingResources",
                      "TidalPlankton",
                      "MonitorEvent",
                       min_date,
                       # "1-1-2013",
                       max_date, 
                       # "12-31-2016",
                      phyto_num,
                      "Station",
                      paste(station.vec, collapse = ",")) %>%
  fromJSON() %>% 
  clean_up()





data.table::fwrite(event.df, file.path(rprojroot::find_rstudio_root_file(), "data/CEDR", "cedr_phyto_event.csv"))
```


COMPARE STEP 1
note: both have 824 elements
```{r}
step_1.df <- event.df

data.table::fwrite(step_1.df, file.path(project.dir, "data/test", "step_1.csv"))

s1_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step1.csv")) %>% clean_up() #%>% mutate(sampledate=as.Date(sampledate))
```



pico data(note that the number above "station" is now 18 rather than 17.  The project id for picoplankton is 18, and 17 for phytoplankton)
```{r}
pico.df <- file.path(url.root,
                      "LivingResources",
                      "TidalPlankton",
                      "Reported",
                       min_date,
                       # "1-1-2013",
                       max_date, 
                       # "12-31-2016",
                       pico_num,
                      "Station",
                      paste(station.vec, collapse = ",")) %>%
  fromJSON() %>% 
  clean_up()


pico.df %>% 
  mutate(reportingvalue = as.character(reportingvalue)) %>% #need this?
data.table::fwrite(file.path(project.dir, "data/CEDR/", "cedr_pico_taxa.csv"))
```


### Read csv's t dataframes


You can run the code from here if you've already pulled from the api
CEDR
```{r}
phyto.df <- data.table::fread(file.path(project.dir, "data/CEDR/", "cedr_phyto_taxa.csv")) %>% clean_up() %>% mutate(sampledate=as.Date(sampledate))

event.df <- data.table::fread(file.path(project.dir, "data/CEDR/", "cedr_phyto_event.csv")) %>% clean_up() %>% mutate(sampledate=as.Date(sampledate))

pico.df <- data.table::fread(file.path(project.dir, "data/CEDR/", "cedr_pico_taxa.csv")) %>% clean_up() %>% mutate(sampledate=as.Date(sampledate))

```

####water quality data

download water quality data:
```{r}
wq.df <- file.path(url.root,
                   "WaterQuality",
                   "WaterQuality",

                   min_date,
                   max_date,
                   # format(min(phyto.df$sampledate) - days(3), "%m-%d-%Y"),
                   # format(max(phyto.df$sampledate) + days(3), "%m-%d-%Y"),
                   "6",  #programIds..."6"" or, "2,4,6""
                   "7,23",#"7,16,23,24",  #projectIds
                   "station",
                   paste(station.vec, collapse = ","),
                   paste(
                     chla,doc,pheo,salinity
                     , sep=",")) %>%
                   #"21,34,74,83") %>% #parameter:21=chla, 34=doc, 74=pheo, 83=salinity
  fromJSON() %>% 
  clean_up()

```
"ProjectId":7,"ProjectIdentifier":"MAIN","ProjectName":"Tidal Mainstem Water Quality Monitoring Project"
"ProjectId":16,"ProjectIdentifier":"PART","ProjectName":"Tidal Non-Traditional Partners"
"ProjectId":23,"ProjectIdentifier":"TRIB","ProjectName":"Tidal Tributary Water Quality Monitoring Project"
"ProjectId":24,"ProjectIdentifier":"TSPECIAL","ProjectName":"Special Tidal Water Quality Monitoring Project"

search for mutant ret3.1
```{r}
wq_mutant.df <- wq.df %>%
  filter(eventid == 425680) #%>%
  #filter(is.na(parameter)) 
```

```{r}
missing_other.df <- wq.df %>%
  mutate(sampledate = as.Date(sampledate)) %>%
  #filter(eventid == 394855 %>% 
  filter(totaldepth <= 5 & station %in% c("tf3.3","tf4.2","tf5.5", "ret3.1","ret4.3","ret3.1")) 
  #filter( station %in% c("tf3.3","tf4.2","tf5.5", "ret3.1","ret4.3","ret3.1") &  (is.na(layer)) |!layer %in% c("s","f","m","p", "ap","b", "bp"))
```

this is a check to see if any wq.df sampledate values fall outside of the date range.  None do
```{r}
print(min(wq.df$sampledate))

print(max(wq.df$sampledate))

narrow_date_range.df <-  wq.df %>%
  mutate(sampledate = as.Date(sampledate)) %>%
  filter( sampledate < as.Date("2013-1-1'") |  sampledate > as.Date("2016-12-31"))


```


```{r}
# step_3.df <- wq_w_pdepth.df
# 
# data.table::fwrite(step_3.df, file.path(project.dir, "data/test", "step_3.csv"))

s3_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step3.csv")) %>% clean_up() #%>% mutate(sampledate=as.Date(sampledate))

```


step 3 anti
```{r}
s3_compare_modified.df <- s3_compare.df %>%
  rename(eventid = wq_eventid)


compare_wq_raw.df <- anti_join(wq.df, s3_compare_modified.df, by = c("eventid"))
```


```{r}
station_check <- s3_compare_modified.df %>%
  filter(station %in% c("sbe5"))
```


```{r}
data.table::fwrite(wq.df, file.path(project.dir, "data/water_quality", "cedr_wq.csv"))
```


```{r}
wq.df <- data.table::fread(file.path(project.dir, "data/water_quality/cedr_wq.csv"),
                            data.table = FALSE,
                           na.strings = c(""))
```

run from war wq(right after CEDR pull) note: this is actually STEP 3
we reduce the wq data to match teh phyto data
```{r}
#create concatinated id for phyto events
phyto.df <- phyto.df %>%
  mutate( sampledate =  as.Date(sampledate)) %>%
  mutate(concat = paste0(station, sampledate))

#create concatinated id for water quality data
wq.df <- wq.df %>%
  mutate( sampledate =  as.Date(sampledate)) %>%
  mutate(concat = paste0(station, sampledate))

#create a vector to store concatinated ids from phyto events
concat_vector <- pull(phyto.df, concat)

#include only the data in water quality data that has a matching concat id with phyto events
wq.df <-wq.df %>%
  filter(concat %in% concat_vector) 

```

this snippet of Zach's code removes any row flagged in the problem column(anything other than na)
28 items are removed from the list
do we want this?
```{r}
# wq.df <- wq.df %>%
#   filter(is.na(problem)
        #) 


         #,
         #parameter %in% c("chla", "doc", "pheo", "salinity") ...removed because these are the only 4 parameters included so
         #the code doesn't actually do anything
         
#)
```

selects columns from wq (eventid recently added)
```{r}
wq.df <- wq.df %>%
  select(station, sampledate, layer, depth, parameter, measurevalue, eventid) %>% #eventid,
  mutate(sampledate=as.Date(sampledate))
```

```{r}
# step_3_test.df <- wq.df
# 
# data.table::fwrite(step_3_test.df, file.path(project.dir, "data/test", "step_3_test.csv"))
```


####Prep Event

```{r}
phyto.df <- phyto.df %>%
  mutate(sampledate = as.Date(sampledate))
```

```{r}
event.df <- event.df %>%
  mutate(sampledate = as.Date(sampledate))
```

this is Zach's code for use with use for (I believe) older data that uses older salzone designations,
it's doing nothing for our current data set (2013-2016)
```{r}
event.df <- event.df %>%
  mutate(sampledate = as.Date(sampledate),
         salzone = case_when(
           salzone %in% c("tf", "fe") ~ "f",
           salzone %in% c("m", "me") ~ "m",
           salzone %in% c("o", "oe") ~ "o",
           salzone %in% c("p", "pe") ~ "p",
           TRUE ~ as.character(NA)
         ))
```

```{r}
pdepth.df <- event.df %>%
  filter(layer %in% c("ap","wc")) %>%
  mutate(sampledate = as.Date(sampledate)) %>%
  select(station, sampledate, pdepth) %>%
  dplyr::distinct()
```

COMPARE STEP 2
both 533
```{r}
step_2.df <- pdepth.df

data.table::fwrite(step_2.df, file.path(project.dir, "data/test", "step_2.csv"))

s2_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step2.csv")) %>% clean_up() #%>% mutate(sampledate=as.Date(sampledate))
```


applies pdepth to water quality dataframe
```{r}
wq_w_pdepth.df <- left_join(wq.df, pdepth.df, by = c("station", "sampledate"))
```

determine if depth is above pdepth
with exception for RET stations
```{r}
wq_w_pdepth.df <- wq_w_pdepth.df %>%
  mutate(above_pdepth = case_when(depth <= pdepth~"Yes",
                                  #depth > pdepth & station %in% c("ret3.1","ret4.3","ret3.1")~"No, but RET",
                                  depth > pdepth~"No"

                                  ))
```

```{r}
# test <- wq_w_pdepth.df %>%
#   filter(above_pdepth == "No, but RET")
```


COMPARE STEP 3
note: 7358 to 7358 in Claire's excel
```{r}
step_3.df <- wq_w_pdepth.df

data.table::fwrite(step_3.df, file.path(project.dir, "data/test", "step_3.csv"))

s3_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step3.csv")) %>% clean_up() #%>% mutate(sampledate=as.Date(sampledate))

```

test script for step 3
```{r}
# step_3_test.df <- step_3.df %>%
#   group_by(eventid) %>% #, sampledate) %>%
#   mutate(total_in_group = n()) %>%
#   summarise() %>%
#   ungroup()
#   
# s3_compare.df <- s3_compare.df %>%
#   mutate( sampledate =  as.Date(sampledate, format = '%m/%d/%Y'))
# 
# s3_compare_test.df <- s3_compare.df %>%
#   group_by(wq_eventid) %>%
#   mutate(total_in_group = n()) %>%
#   summarise() %>%
#   ungroup()
# 
# id_vector <- pull(s3_compare_test.df, wq_eventid)
# 
# step_3_by_id <-wq.df %>%
#   filter(eventid %in% id_vector)
# 
# step_3_to_exclude <- wq.df %>%
#   filter(!eventid %in% id_vector)
# 
# s3_wq_dates.df <- data.table::fread(file.path(project.dir, "data/test/", "wq_dates.csv")) %>% clean_up() %>%
#   mutate( sampledate =  as.Date(sampledate, format = '%m/%d/%Y'))
#   # group_by(sampledate) %>%
#   # mutate(total_in_group = n()) %>%
#   # summarise() %>%
#   # ungroup()
# 
# test_7358 <- step_3.df %>%
#   #filter(is.na(problem))
#   filter(layer %in% c("s","a","p","m")) %>%
# 
# test_missing <-  

  
```

filters out dpeths below pdepth
making an exception for any data missing pdepth of station tf4.2
by joining data that meet that criteria back in
```{r}
# missing_pdepth.df <- wq_w_pdepth.df %>%
#   filter( (is.na(pdepth)& station %in% c("tf3.3","tf4.2","tf5.5", "ret3.1","ret4.3","ret3.1")) 
# )
# 
# missing_other_pd.df <- left_join(missing_other.df, pdepth.df, by = c("station", "sampledate")) %>%
#   filter(totaldepth <= 5 & station %in% c("ret3.1","ret4.3") & pdepth <=1 ) 

```

```{r}
wq_above_pdepth.df <- wq_w_pdepth.df%>%
  filter(depth <= pdepth)


#wq_above_pdepth.df <- full_join(wq_above_pdepth.df, missing_pdepth.df)

#& (!station %in% c("tf3.3","tf4.2","tf5.5", "ret3.1","ret4.3","ret3.1") & layer != "ap"))


```


check for missing(station and date combos that are present in event.df but not represtented in wq_above_pdepth.df) 
```{r}
step_4.vec <- c("station", "sampledate", "layer", "pdepth", "concat", "depth", "parameter", "measurevalue", "above_pdepth", "eventid")

#function for finding backbone values missing from recently modified data and add them into recently modified(latest) date
find_missing <- function(data_backbone, source_data, modified_data, step_vector) {
  missing.df <- anti_join(data_backbone, modified_data, by = c("station","sampledate"))
  
  missing.df <-  missing.df %>%
    mutate( sampledate =  as.Date(sampledate)) %>%
    mutate(concat = paste0(station, sampledate))
  
  source_data <- source_data %>%
    mutate( sampledate =  as.Date(sampledate)) %>%
    mutate(concat = paste0(station, sampledate))
  
  concat_vector2.vec <- pull(missing.df, concat)
  
  missing_full.df <-source_data %>%
    filter(concat %in% concat_vector2.vec) 
  
  modified_data <- modified_data %>%
  mutate( sampledate =  as.Date(sampledate)) %>%
  mutate(concat = paste0(station, sampledate))

  final.df <- full_join(modified_data, missing_full.df, by = step_vector)
                          #c("station", "sampledate", "layer", "pdepth", "concat", "depth", "parameter", "measurevalue", "above_pdepth", "eventid"))
  
  return(final.df)
}
#show the mssing values
name_missing <- function(data_backbone, source_data, modified_data, step_vector) {
  missing.df <- anti_join(data_backbone, modified_data, by = c("station","sampledate"))
  
  missing.df <-  missing.df %>%
    mutate( sampledate =  as.Date(sampledate)) %>%
    mutate(concat = paste0(station, sampledate))
  
  source_data <- source_data %>%
    mutate( sampledate =  as.Date(sampledate)) %>%
    mutate(concat = paste0(station, sampledate))
  
  concat_vector2.vec <- pull(missing.df, concat)
  
  final.df <-source_data %>%
    filter(concat %in% concat_vector2.vec) 
  
    return(final.df)
}

wq_above_pdepth.df <- find_missing(event.df, wq_w_pdepth.df, wq_above_pdepth.df, step_4.vec)

# #finds instances of station/sampledate combo that are missing from wq
# missing.df <- anti_join(event.df,wq_above_pdepth.df, by = c("station", "sampledate"))
# 
# #standardize date format and add a unique identifier to missing 
# missing.df <- missing.df %>%
#   mutate( sampledate =  as.Date(sampledate)) %>%
#   mutate(concat = paste0(station, sampledate))
# 
# #standardize date format and add a unique identifier to wq
# wq_w_pdepth.df <- wq_w_pdepth.df %>%
#   mutate( sampledate =  as.Date(sampledate)) %>%
#   mutate(concat = paste0(station, sampledate))
# 
# #create a vector to store concatinated ids from the missing combos
# concat_vector2.vec <- pull(missing.df, concat)
# 
# #uses the combos in missing.df to retrieve the event data for the missing values
# missing_full.df <-wq_w_pdepth.df %>%
#   filter(concat %in% concat_vector2.vec) 
# 
# #adds a concat id to wq_above_pdepth
# wq_above_pdepth.df <- wq_above_pdepth.df %>%
#   mutate( sampledate =  as.Date(sampledate)) %>%
#   mutate(concat = paste0(station, sampledate))
# 
# #joins the missing values back into most recent wq df
# wq_above_pdepth.df <- full_join(wq_above_pdepth.df, missing_full.df, by = c("station", "sampledate", "layer", "pdepth", "concat", "depth", "parameter", "measurevalue", "above_pdepth", "eventid"))
```


COMPARE STEP 4
note: 3483 to 3483 in Claire's excel
```{r}
step_4.df <- wq_above_pdepth.df

data.table::fwrite(step_4.df, file.path(project.dir, "data/test", "step_4.csv"))

s4_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step4.csv")) %>% clean_up() #%>% mutate(sampledate=as.Date(sampledate))
```

code to compare dataframes for testing step 4:
```{r}
step_4_modified.df <- step_4.df %>%
  mutate(sampledate = as.Date(sampledate)) %>%
  #select(-sampledate, above_pdepth) %>%
  mutate(author = "Luke")

# s4_compare.df <- s4_compare.df %>%
#   mutate(sampledate = as.Date(sampledate))

s4_compare_modified.df <- s4_compare.df %>%
  rename(above_pdepth = `above_p_depth?`) %>%
  rename(eventid = wq_eventid) %>%
  rename(pdepth = p_depth) %>%
  select(station, sampledate, layer, depth, parameter, measurevalue, eventid, pdepth, above_pdepth) %>%
  #select(-sampledate, -above_pdepth) %>%
  mutate(author = "Claire")


```


the objects in diff_check_step_4.df were the 4 entries that exist in Claire's data but not in mine. Exceptions written for such cases, except one which does not exist in my data:
```{r}

#diff_check.df <- left_join(step_4_modified.df, s4_compare_modified.df)


LV_diff_check_step_4.df <- anti_join(step_4_modified.df, s4_compare_modified.df, by = c("station", "depth", "parameter", "measurevalue", "eventid", "pdepth")) #"layer",

C_diff_check_step_4.df <- anti_join(s4_compare_modified.df, step_4_modified.df,  by = c("station", "depth", "parameter", "measurevalue", "eventid", "pdepth")) #"layer",

# author_check.df <- diff_check.df %>%
#   filter(author == "Claire")
```


Step 5:

this code isolates exceptions that need to be added back in after the following chunk of code
```{r}
# 
# step5_exceptions <- wq_above_pdepth.df %>%
#   filter(above_pdepth == "No, but RET")
#   filter(!layer %in% c("s","f","m","p", "ap"))

```


generates new dataframe with new parameter s_chla (531 items, should be 533)
```{r}
s_chla.df <- wq_above_pdepth.df %>%
  filter(layer == "s", 
         parameter == "chla") %>% 
  unite(parameter, c("layer", "parameter"), remove = FALSE) #%>%
  # filter(depth <= pdepth) #%>%
  #filter(parameter=="s_chla")
  #filter(eventid==425680 | eventid==394855)
```

```{r}
# s_chla.df <- s_chla.df %>%
#   group_by(station, sampledate) %>%
#   mutate(avg_di_s_chla = mean(measurevalue, na.rm = TRUE)) %>%
#   ungroup()
```

Average replicates from s_chla ...measure value average
```{r}
di_s_chla.df <- s_chla.df %>%
  group_by(station, sampledate, depth) %>%
  #do not remove NAs
  mutate(measurevalue_averaged = mean(measurevalue)) %>%
  distinct(station, sampledate, depth, eventid, layer, parameter, measurevalue_averaged, concat) %>%
  ungroup()

```


find missing values in step 5
```{r}
step_5.vec <- c("station", "sampledate", "layer", "concat", "depth", "parameter", "eventid")


#grabs missing values
missing_s_chla.df <- name_missing(event.df, wq_above_pdepth.df, di_s_chla.df, step_5.vec) %>%
  #reduce to only a single isntance for each eventid
  distinct(eventid, station, sampledate, concat) %>%
  mutate(parameter =  "s_chla") %>%
  mutate(sampledate = as.Date(sampledate)) %>%
  mutate()

# creates a vector of the unqiue ids of the missing values
missing_ids.vec <- pull(missing_s_chla.df, eventid) 

# checks ids against source, which is totally redundant
missing_full.df <-wq_above_pdepth.df %>%
  filter(eventid %in% missing_ids.vec ) 

#join missing values into di_s_chla.df with blank values
di_s_chla.df <- full_join(di_s_chla.df, missing_s_chla.df, by = c("station", "sampledate", "eventid", "parameter", "concat"))

# test.df <- di_s_chla_test.df %>%
#   filter(is.na(measurevalue_averaged))
  
```


I have eventid 39855 with s_chla in my wq data
this is the check:
```{r}
mystrey.df <- wq_above_pdepth.df %>%
  filter(eventid == 394855)

mysery2.df <- event.df %>%
  filter(station == "tf4.2" & sampledate =="2014-07-15")
  
mystery3.df <- wq.df %>%
  filter(eventid == 394855)

mystery4.df <- di_s_chla.df %>%
  filter(eventid == 394855)
```




STEP 5 COMPARE
my 533 to Claire's 531(was 533?)
```{r}
step_5.df <- di_s_chla.df

data.table::fwrite(step_5.df, file.path(project.dir, "data/test", "step_5.csv"))

s5_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step5.csv")) %>% clean_up() #%>% mutate(sampledate=as.Date(sampledate))
```

```{r}
step_5_modified.df <- step_5.df %>%
  mutate(sampledate = as.Date(sampledate)) %>%
  #select(-sampledate, above_pdepth) %>%
  mutate(author = "Luke") %>%
  clean_up() %>%
  mutate(measurevalue_averaged = as.numeric(measurevalue_averaged))

# s5_compare.df <- s5_compare.df %>%
#   mutate(sampledate = as.Date(sampledate))

s5_compare_modified.df <- s5_compare.df %>%
  rename(eventid = wq_eventid) %>%
  rename(measurevalue_averaged = average_of_measurevalue) %>%
  #rename(pdepth = p_depth) %>%
  #select(station, sampledate, layer, depth, parameter, measurevalue, eventid, pdepth, above_pdepth) %>%
  #select(-sampledate, -above_pdepth) %>%
  mutate(author = "Claire") %>%
  clean_up() %>%
  mutate(measurevalue_averaged = as.numeric(measurevalue_averaged))


C_diff_check_step_5.df <- anti_join(s5_compare_modified.df, step_5_modified.df, by = c("station",  "parameter", "measurevalue_averaged", "eventid", "layer"))

C_diff_check_step_5.df <- C_diff_check_step_5.df%>%
  mutate(measure_type = typeof(measurevalue_averaged)) %>%
  filter(eventid==425680 | eventid==394855)

LV_diff_check_step_5.df <- anti_join(step_5_modified.df, s5_compare_modified.df, by = c("station", "measurevalue_averaged", "parameter", "eventid","layer")) 

LV_diff_check_step_5.df <- LV_diff_check_step_5.df%>%
  mutate(measure_type = typeof(measurevalue_averaged))
```


```{r}
# wq_rep_check.df <- wq_above_pdepth.df %>%
#   select(station, sampledate, depth, parameter) %>%
#   distinct()
```



Averge replicates for the rest of the data ...measure value average 
```{r}
wq_above_pdepth.df <- wq_above_pdepth.df %>%
  group_by(station, sampledate, depth, parameter) %>%
  #do not remove NAs
  mutate(measurevalue_averaged = mean(measurevalue)) %>%
  distinct(station, sampledate, depth, parameter,measurevalue_averaged) %>%
  ungroup()
```

COMPARE STEP 6 
my 3366 to Claire's is 3357(was 3366)
```{r}
step_6.df <- wq_above_pdepth.df

data.table::fwrite(step_6.df, file.path(project.dir, "data/test", "step_6.csv"))

s6_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step6.csv")) %>% clean_up()

C_diff_check_step_6.df <- anti_join(step_6.df,s6_compare.df, by = c(
  #"station", "depth","parameter", 
  "measurevalue_averaged"
  )) 

LV_diff_check_step_6.df <- anti_join(s6_compare.df, step_6.df, by = c(
  #"station", "depth", "parameter", 
  "measurevalue_averaged")) 


```


```{r}
wq_above_pdepth.df <- wq_above_pdepth.df %>%
  group_by(station, sampledate, parameter) %>%
  mutate(depth_integrated_value = mean(measurevalue_averaged)) %>%
  distinct(station, sampledate, depth_integrated_value) %>%
  ungroup()
```

COMPARE STEP 7 
mine is 2028 to Claire's 2026(was 2028)
```{r}
step_7.df <- wq_above_pdepth.df

data.table::fwrite(step_7.df, file.path(project.dir, "data/test", "step_7.csv"))

s7_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step7.csv")) %>% clean_up() %>% 
  rename(depth_integrated_value =`depth-integrated_value`)


C_diff_check_step_7.df <- anti_join(step_7.df,s7_compare.df, by = c(#"station", "parameter", 
  "depth_integrated_value")) 

LV_diff_check_step_7.df <- anti_join(s7_compare.df, step_7.df, by = c(#"station", "parameter", 
  "depth_integrated_value")) 
```

join surface chloraphyl into water quality data
measurevalued_averaged is renamed depth_integrated_value to match water quality naming convention
(note:check against Claire's data to confirm that s_chla depth integrated values look right just to be sure)
```{r}
di_s_chla.df <- di_s_chla.df %>% 
  rename(depth_integrated_value = measurevalue_averaged)
  

wq_all.df <- full_join(wq_above_pdepth.df, di_s_chla.df, by = c("station", "sampledate", "parameter", "depth_integrated_value"))

# wq_all.df <- wq_all.df %>%
#   filter(parameter != "s_chla")
  
```


COMPARE STEP 8
my 2561 to Claire's 2555(was 2558)
```{r}
print(2028 + 533)


step_8.df <- wq_all.df

data.table::fwrite(step_8.df, file.path(project.dir, "data/test", "step_8.csv"))

s8_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step8.csv")) %>% clean_up() %>% 
  rename(depth_integrated_value =`depth-integrated_value`)

C_diff_check_step_8.df <- anti_join(step_8.df,s8_compare.df, by = c("depth_integrated_value")) 

LV_diff_check_step_8.df <- anti_join(s8_compare.df, step_8.df, by = c("depth_integrated_value")) 
```

filter out dates outside Mar-May and Jul-Sept
borrowed this chunk from Zach
```{r}
wq_warm.df <- wq_all.df %>%
  mutate(month = month(sampledate),
         season = case_when(
           month %in% c(3, 4, 5) ~ "spring",
           month %in% c(7, 8, 9) ~ "summer",
           TRUE ~ "remove"
          )) 
  #%>% 
  # filter(season %in% c("spring", "summer"))
```


assign salzones...work in progress
```{r}
wq_sal.df <- wq_warm.df %>%
  filter(parameter == "salinity")

wq_sal.df <- wq_sal.df %>%
  mutate(salzone = case_when(
    parameter == "salinity" & depth_integrated_value >0 & depth_integrated_value <= 0.5 ~ "F",
    parameter == "salinity" & depth_integrated_value > .5 &  depth_integrated_value <= 5 ~ "O",
    parameter == "salinity" & depth_integrated_value > 5 & depth_integrated_value <= 18 ~ "M",
    parameter == "salinity" & depth_integrated_value > 18~ "P")) %>%
    mutate(concat = paste0(station, sampledate)) 

wq_sal_id.df <- wq_sal.df %>%
  distinct(concat, salzone)

wq_warm.df <- wq_warm.df %>%
    mutate(concat = paste0(station, sampledate))   


wq_warm_sal.df <- left_join(wq_warm.df, wq_sal_id.df, by = c("concat"))#, "salzone"))



```




Find events without salinity and assign salinity when possible...Assign F salzone to some station/season instances based on known salinity profiles
```{r}
# salinities are less than 0.5 ppt, or "F" more than 90% of the time: CB1.1, ET5.1, TF1.5, TF2.3, TF4.2, TF5.5 in Spring;								
# CB1.1, TF2.3, TF4.2, TF5.5 in Summer. We can assume their Salzone is F and replace 61 of the 78 blanks.								
wq_no_sal.df <- anti_join(wq_warm_sal.df, wq_sal_id.df, by = c("concat"))

wq_sal_fill.df <-  wq_no_sal.df %>%
  distinct(concat, station, sampledate, season, salzone) %>%
  mutate(salzone = case_when((station %in% c("cb1.1", "tf2.3", "tf4.2","tf5.5" ) & is.na(salzone)) | (season == "spring" & station %in% c("et5.1", "tf1.5")& is.na(salzone))
         ~ "F", TRUE ~ salzone  ))

#test number of exceptions above code is catching
wq_sal_filled.df <- wq_sal_fill.df %>%
  filter(salzone == "F")

test_na.df <- wq_sal_fill.df %>%
  filter(is.na(salzone))
```

Add the data assigned salzones back into backbone
```{r}
wq_warm_sal_added.df <- left_join(wq_warm_sal.df, wq_sal_filled.df, by= c("concat", "salzone","station","sampledate", "season"))

# test to determine if we are retaining the right values
test.df <- anti_join(wq_warm.df, wq_warm_sal_added.df,  by = c("concat", "station","sampledate", "season", "parameter", "month", "depth_integrated_value"))
```



bring in Jackies data to compare salzones against
import jackie's salzones if data falls within the applicable date range and is missing salzone data
note:this should be the last method of acquiring salzone data implemented
(this code is untested)
```{r}
#jackie.df <- data.table::fread(file.path(project.dir, "data/Jackie/", "JMJ_PIBI_Salzone_Data.csv"))
jackie_salzones.df <- readxl::read_excel(file.path(project.dir, "data/Jackie/JMJ_PIBI_Salzone_Data.xlsx"),
                         sheet = "JMJ Salzone+Scores") %>% clean_up() %>%
  rename(salzone = ibi_salzone)

wq_need_sal.df <- wq_warm_sal_added.df %>%#wq_sal_test.df %>%
  mutate(year = year(sampledate)) %>%
  filter(year >= 1984 & year <= 2011 & is.na(salzone))

#join jackie salzone values to wq_need_sal by id, but only if sal needed is not an empty dataframe
if (nrow(wq_need_sal.df) > 1) {
  wq_has_sal.df <- left_join(wq_need_sal.df, jackie_salzones.df, by= c("concat", "salzone"))

  #join wq_need_sal to main wq data
  wq_warm_sal_added.df <- left_join(wq_warm_sal_added., wq_has_sal.df, by= c("concat", "salzone"))
}
             
```


```{r}
wq_warm.wide <- wq_warm_sal_added.df %>%
  select(-layer, -depth,-eventid,-concat) %>%
  spread(parameter, depth_integrated_value)
```


COMPARE STEP 9
```{r}
step_9.df <- wq_warm.wide

data.table::fwrite(step_9.df, file.path(project.dir, "data/test", "step_9.csv"))

s9_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step9.csv")) %>% clean_up() 

C_diff_check_step_9.df <- anti_join(step_9.df,s9_compare.df, by = c("chla", "s_chla", "pheo", "salinity", "doc")) 

LV_diff_check_step_9.df <- anti_join(s9_compare.df, step_9.df, by = c("chla", "s_chla", "pheo", "salinity", "doc")) 
```

remove winter and fall
```{r}
wq_final.df <- wq_warm.wide %>%

 filter(season %in% c("spring", "summer"))
```
COMPARE STEP 10

```{r}
step_10.df <- wq_final.df

data.table::fwrite(step_10.df, file.path(project.dir, "data/test", "step_10.csv"))

s10_compare.df <- data.table::fread(file.path(project.dir, "data/test/", "C_step10.csv")) %>% clean_up() 

C_diff_check_step_10.df <- anti_join(step_10.df,s10_compare.df, by = c("chla", "s_chla", "pheo", "salinity", "doc")) 

LV_diff_check_step_10.df <- anti_join(s10_compare.df, step_10.df, by = c("chla", "s_chla", "pheo", "salinity", "doc"))
```

itis
```{r}
carbon.df <- readxl::read_excel(file.path(project.dir, "data/carbon/carbon_list_2014.xlsx"),
                         sheet = "OldBiomassEstimates") %>% clean_up()
```

find temporary tsn values
```{r}
bad_tsn.df <- carbon.df %>%
  #filter(tsn == "bay0001")
  filter(str_detect(tsn, "^bay"))

```

carbon data needs to be reformatted to work with bay data
```{r}
carbon_test.df <- carbon.df %>%
  mutate(tsn =  gsub("(?<![0-9])0+", "", tsn, perl = TRUE)) %>%
  rename(latinname = lbl) %>%
  rename(carbon = `carbon_(picogram_c_per_cell)`) %>%
  mutate(tsn = as.integer(tsn)) %>%
  mutate(size = case_when(size == "not_applicable"~ as.character(NA), TRUE ~size))

```

```{r}
col.class.vec <- c("samplenumber" = "character",
                   "tsn" = "integer",
                   "speccode" = "character",
                   "reportingvalue" = "integer")

bay.temp <- data.table::fread(file.path(project.dir, "data/CEDR/cedr_phyto_taxa.csv"),
                            data.table = FALSE,
                            colClasses = col.class.vec)

# bay.temp <- bay.temp %>%
#   mutate(tsn =)
```

test join
```{r}
test_join <- left_join(bay.temp, carbon_test.df, by = c("tsn","latinname","size"))
```


working to resolve missing carbons, etc.
```{r}
test <- carbon_test.df %>%
  filter(tsn == 2294)
  #filter(latinname == "melosira_nummuloides")
```


